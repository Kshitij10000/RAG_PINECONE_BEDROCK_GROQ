{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kshit\\Desktop\\rag_pine\\rag_env\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "c:\\Users\\kshit\\Desktop\\rag_pine\\rag_env\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kshit\\Desktop\\rag_pine\\rag_env\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from typing import List\n",
    "import boto3\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.schema import Document\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.chains import RetrievalQA\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(pdf_path):\n",
    "    try:\n",
    "        pdf_reader = PdfReader(pdf_path)\n",
    "        text = ''\n",
    "        for page in pdf_reader.pages:\n",
    "            extracted = page.extract_text()\n",
    "            if extracted:\n",
    "                text += extracted\n",
    "        if not text:\n",
    "            logger.warning(\"No text extracted from PDF.\")\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"The file {pdf_path} does not exist.\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during PDF extraction: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_chunks(text: str) -> List[Document]:\n",
    "    \"\"\"Divide raw string data into chunks.\"\"\"\n",
    "    try:\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        logger.info(f\"Created {len(chunks)} text chunks.\")\n",
    "        return [Document(page_content=chunk) for chunk in chunks]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in create_text_chunks: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(chunks: List[Document]) -> PineconeVectorStore:\n",
    "    \"\"\"Store data into vector database.\"\"\"\n",
    "    try:\n",
    "        embeddings = BedrockEmbeddings()\n",
    "        index_name = \"rag-aws\"\n",
    "        vector_store = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        logger.info(\"Vector store created successfully.\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in create_vector_store: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm() -> Bedrock: \n",
    "    \"\"\"Initialize the Bedrock LLM.\"\"\"\n",
    "    try:\n",
    "        bedrock_client = boto3.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            region_name=\"us-east-1\"  # replace with your preferred region\n",
    "        )\n",
    "        llm = Bedrock(\n",
    "            model_id=\"meta.llama2-70b-chat-v1\",\n",
    "            client=bedrock_client,\n",
    "            model_kwargs={\n",
    "                \"max_gen_len\": 512,\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "        )\n",
    "        logger.info(\"LLM initialized successfully.\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in initialize_llm: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Function to Create QA Chain\n",
    "def create_qa_chain(llm: Bedrock, docsearch: PineconeVectorStore) -> RetrievalQA:\n",
    "    try:\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",  # 'stuff' combines all retrieved docs into a single prompt\n",
    "            retriever=docsearch.as_retriever(search_kwargs={\"k\": 5}),\n",
    "            return_source_documents=False  # Set to True if you want to see source documents\n",
    "        )\n",
    "        logger.info(\"QA chain created successfully.\")\n",
    "        return qa_chain\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in create_qa_chain: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text (first 1000 characters):\n",
      "Kshitij  Sarve  \n",
      "Education  Mob:  +91-9579360733  \n",
      "Mail:  kshitijsarve2001@gmail.com  \n",
      "GitHub:  https://github.com/Kshitij10000  \n",
      "LinkedIn: https://shorturl.at/5Nh3U  \n",
      "Deogiri  Institute  of Engineering  and Management  Studies,  Aurangabad,  MH 2020 – 2024  \n",
      "B. Tech  in CSE  (Artificial  Intelligence  and Machine Learning)  CGPA–7.9 Aurangabad,  Maharashtra  \n",
      " \n",
      "Experience  \n",
      "Aldrich  Research  Services  (USA  based  Private  Equity  Firm)  February  2024  – May  2024  \n",
      "AI Developer  Intern  Onsite  \n",
      "Projects:  \n",
      "Candidate  Recommendation  Systems  (CRS)  \n",
      "• Developed  AI solutions  that boosted  workflow  efficiency  by 30%  through  automation  and real-time  data  analysis.  \n",
      "• Built AI -powered  candidate  recommendation  systems,  increasing  successful  hires  by 25%  and reducing  screening  time  by \n",
      "50%.  \n",
      "• Enhanced  GPT  based  chatbot  with  90%  accuracy,  decreasing  customer  service  response  times  by 40%.  \n",
      "• Continuously  improved  AI models,  achieving  a 15% accurac\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Execute QA Pipeline (Partial)\n",
    "pdf_file = r\"C:\\Users\\kshit\\Desktop\\Kshitij_Sarve_Resume.pdf\"\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "raw_txt = extract_text_from_pdfs(pdf_file)\n",
    "if not raw_txt:\n",
    "    logger.error(\"No text extracted. Exiting.\")\n",
    "else:\n",
    "    print(\"Extracted Text (first 1000 characters):\")\n",
    "    print(raw_txt[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created 4 text chunks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 4\n",
      "Sample Chunk:\n",
      "Kshitij  Sarve  \n",
      "Education  Mob:  +91-9579360733  \n",
      "Mail:  kshitijsarve2001@gmail.com  \n",
      "GitHub:  https://github.com/Kshitij10000  \n",
      "LinkedIn: https://shorturl.at/5Nh3U  \n",
      "Deogiri  Institute  of Engineering  and Management  Studies,  Aurangabad,  MH 2020 – 2024  \n",
      "B. Tech  in CSE  (Artificial  Intelligence  and Machine Learning)  CGPA–7.9 Aurangabad,  Maharashtra  \n",
      " \n",
      "Experience  \n",
      "Aldrich  Research  Services  (USA  based  Private  Equity  Firm)  February  2024  – May  2024  \n",
      "AI Developer  Intern  Onsi\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create text chunks\n",
    "chunks = create_text_chunks(raw_txt)\n",
    "print(f\"Number of Chunks: {len(chunks)}\")\n",
    "if chunks:\n",
    "    print(\"Sample Chunk:\")\n",
    "    print(chunks[0].page_content[:500])  # Print first 500 characters of the first chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['c:\\\\Users\\\\kshit\\\\Desktop\\\\rag_pine\\\\rag_env\\\\Lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n",
      "ERROR:__main__:Error in create_vector_store: Index 'rag-aws' not found in your Pinecone project. Did you mean one of the following indexes: testfiles\n",
      "ERROR:__main__:Failed to create vector store.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create vector store\n",
    "doc_search = create_vector_store(chunks)\n",
    "if doc_search is None:\n",
    "    logger.error(\"Failed to create vector store.\")\n",
    "else:\n",
    "    # Optionally, print the number of vectors stored\n",
    "    index_name = \"rag-aws\"\n",
    "    index = pinecone.Index(index_name)\n",
    "    try:\n",
    "        index_stats = index.describe_index_stats()\n",
    "        num_vectors = index_stats.get('total_vector_count', 0)\n",
    "        print(f\"Number of vectors in Pinecone index '{index_name}': {num_vectors}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving Pinecone index stats: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['c:\\\\Users\\\\kshit\\\\Desktop\\\\rag_pine\\\\rag_env\\\\Lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n",
      "ERROR:__main__:Error in create_vector_store: Index 'rag-aws' not found in your Pinecone project. Did you mean one of the following indexes: testfiles\n"
     ]
    }
   ],
   "source": [
    "doc_search = create_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "C:\\Users\\kshit\\AppData\\Local\\Temp\\ipykernel_7788\\1125099038.py:8: LangChainDeprecationWarning: The class `Bedrock` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockLLM``.\n",
      "  llm = Bedrock(\n",
      "INFO:__main__:LLM initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "llm = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error in create_qa_chain: 'NoneType' object has no attribute 'as_retriever'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_chain = create_qa_chain(llm, doc_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:QA chain is not initialized.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Test the QA System\n",
    "if qa_chain:\n",
    "    try:\n",
    "        user_question = \"Who is Kshitij Sarve?\"\n",
    "        response = qa_chain.invoke(user_question)\n",
    "        print(\"Answer:\", response['result'])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during QA: {e}\")\n",
    "else:\n",
    "    logger.error(\"QA chain is not initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
